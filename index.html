<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>AI in Real</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <meta name="keywords" content="Concerted Responsive web template, Bootstrap Web Templates, Flat Web Templates, Android Compatible web template,
	Smartphone Compatible web template, free webdesigns for Nokia, Samsung, LG, SonyErricsson, Motorola web design"/>
    <script type="applijewelleryion/x-javascript">
         addEventListener("load", function() { setTimeout(hideURLbar, 0); }, false); function hideURLbar(){ window.scrollTo(0,1); }

    </script>
    <link href="css/bootstrap.css" rel='stylesheet' type='text/css'/>
    <!-- Custom Theme files -->
    <link href='//fonts.googleapis.com/css?family=Viga' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Roboto+Condensed' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:400,700,300' rel='stylesheet' type='text/css'>
    <link href="css/style.css" rel='stylesheet' type='text/css'/>
    <link rel="stylesheet" href="css/flexslider.css" type="text/css" media="screen"/>
    <script src="js/jquery-1.11.1.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script type="text/javascript" src="js/move-top.js"></script>
    <script type="text/javascript" src="js/easing.js"></script>
    <script type="text/javascript">
        jQuery(document).ready(function ($) {
            $(".scroll").click(function (event) {
                event.preventDefault();
                $('html,body').animate({scrollTop: $(this.hash).offset().top}, 1200);
            });
        });
    </script>
    <script type="text/javascript">
        $(document).ready(function () {

            $().UItoTop({easingType: 'easeOutQuart'});
        });
    </script>
    <script src="js/jquery.chocolat.js"></script>
    <link rel="stylesheet" href="css/chocolat.css" type="text/css" media="all"/>
    <!--light-box-files -->
    <script type="text/javascript">
        $(function () {
            $('#example1 a').Chocolat();
        });
    </script>
    <script type="text/javascript">
        $(function () {
            $('#portfolio a').Chocolat();
        });
    </script>
    <!-- animation-effect -->
    <link href="css/animate.min.css" rel="stylesheet">
    <script src="js/wow.min.js"></script>
    <script>
        new WOW().init();
    </script>
    <!-- //animation-effect -->
</head>

<body>
<div class="banner w3l-1">
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <div class="navbar-header wow fadeInLeft animated animated" data-wow-delay=".5s" style="visibility: visible; animation-delay: 0.5s; animation-name: fadeInLeft;">

                <!--toggle button-->
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>
            <div id="navbar" class="navbar-collapse collapse">
                <ul class="nav navbar-nav">
                    <li><a href="#cfp" class="scroll">Call for Papers</a></li>
                    <li><a href="#schedule" class="scroll">Schedule</a></li>
                    <li><a href="#speakers" class="scroll">Invited Speakers</a></li>
                    <li><a href="#papers" class="scroll">Accepted Papers</a></li>
                    <li><a href="#organizers" class="scroll">Organizers</a></li>
                </ul>
                <div class="clearfix"></div>
            </div>
        </div>
    </nav>
</div>

<div class="container"  style="padding-top: 100px;">
    <div class="page-header">
        <div class="row">
            <div class="col-xs-12">
                <center>
                    <h1>Future Impact of AI in Real-World Applications</h1>
                </center>
                <center>
                    <h3>ACPR 2021 Workshop, Jeju Island, Korea</h3>
                </center>
                <br>
                <center>
                    Friday November 12 2021, 9:30am - 17:00pm
                </center>
                <center>
<!--                    Location: <b>Room 318A</b>-->
                </center>
            </div>

        </div>
    </div>
    <hr>

    <div class="row" id="intro">
        <div class="col-md-12" style="text-align: center">
            <img width="90%" src="images/jeju-intro.jpg">
        </div>
    </div>
    <hr>
    <div class="row" id="cfp">
        <div class="col-xs-12">
            <h2>Introduction</h2>
            <br>
            <div class="row" style="padding: 15px 0px 15px 25px;">
                <div class="col-xs-12">
                    <p>
                        The workshop will focus on various area of future impact of AI. The aim of this workshop is to bring
                        researchers and scientists from academia, medical area with engineers from industry together to discuss
                        about various impact of cutting-edge technologies of AI in future society. The workshop will take a deep
                        dive into the capabilities of Edge Insights for Academia and Industrial via a tutorial utilizing
                        real-world AI applications. For example, breast cancer can be detected via smartphone level infrared
                        camera for detecting lesion and target mass at home. Despite the existence of some commercial AI systems
                        such as autonomous vehicle, we are at the beginning of a long research pathway towards a future
                        generation of deep AI. The workshop focuses on numerical and computational aspects of future impact of
                        AI and on these relations to various AI techniques.
                    </p>
                    <br>
                    <h4>Call for papers</h4>
                    <p>
                        We welcome submissions on the following topics, including but not limited to:
                    </p>
                    <ur>
                        <li>Image Generation and Translation</li>
                        <li>Semantic segmentation/ Instance Segmentation</li>
                        <li>Recognition: detection, tracking, Anomaly detection, localization</li>
                        <li>Image processing: denoising, enhancement, super resolution</li>
                        <li>3D computer vision, stereo matching</li>
                        <li>NLP (natural language processing)</li>
                        <li>Voice Recognition: STT(Speech to Text)</li>
                        <li>Reinforcement Learning</li>
                        <li>Sensor fusion with AI</li>
                        <li>Game with AI</li>

                    </ur>
                </div>
            </div>
        </div>
    </div>


    <hr>
    <div class="row" id="dates">
        <div class="col-xs-12">
            <h2>Important Dates</h2>
            <br>
            <table class="table table-striped">
                <tbody>
                <tr>
                    <td>Paper Submission Deadline</td>
                    <!--                    <td><s style="color:darkred;">July 29</s> July 31, 2019 (23:59 Pacific time)</td>-->
                    <td>October 10, 2021 (23:59 Pacific time)</td>
                </tr>
                <tr>
                    <td>Notification to Authors</td>
                    <!--                    <td><s style="color:darkred;">August 16</s> August 18, 2019</td>-->
                    <td>October 17, 2021</td>
                </tr>
                <tr>
                    <td>Camera-Ready Deadline</td>
                    <td>October 24, 2021</td>
                </tr>
                <tr>
                    <td>Workshop Date</td>
                    <td>November 12, 2021 (Morning)</td>
                </tr>
                </tbody>
            </table>
        </div>
    </div>

    <hr>
    <div class="row">
        <div class="col-xs-12">
            <h2>Submission</h2>
            <br>
            <div class="row" style="padding: 0px 0px 15px 25px;">
                <div class="col-md-9">
                    <p>
<!--                         Papers will be limited to 2~3 pages according to the LNCS format (c.f. main conference authors guidelines).
                        All papers will be reviewed by at least two reviewers with double blind policy.
                        Papers will be selected based on relevance, significance and novelty of results, technical merit, and clarity of presentation.
                        Papers will be published in workshop homepage. -->
			Extended Abstracts: Participants are encouraged to submit preliminary ideas that have not been previously published in conferences or journals.
			We also invite papers published in other conferences and journals (2021 only) to facilitate new collaborations.
			Submissions may consist of one page abstract and one additional page for references (using the template described above).
			The expanded abstract will be posted on the website only during the workshop period.
                    </p>
                    <p>
                        All the papers should be submitted to workshop chairs, Prof. Lee (segeberg@kmu.ac.kr) and Prof. Ko (niceko@kmu.ac.kr)
                    </p>
                </div>
            </div>


        </div>
    </div>


    <hr>
    <div class="row" id="schedule">
        <div class="col-xs-12">
            <h2>Workshop Schedule</h2>
            <br>
            <table class="table schedule" style="border:none !important;">
                <thead class="thead-light">
                <tr>
                    <th>#</th>
                    <th>Time</th>
                    <th>Item</th>
                </tr>
                </thead>
                <tbody>
                <tr>
                    <td>1</td>
                    <td>9:30am - 10:00am</td>
                    <td>Welcome and Opening Remarks</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td>10:00am - 10:40am</td>
                    <td>Invited Speaker I</td>
                </tr>
<!--                <tr class="noline">-->
<!--                    <td></td>-->
<!--                    <td></td>-->
<!--                    &lt;!&ndash;<td>8:35am - 9:20am</td>&ndash;&gt;-->
<!--                    <td><s>Yusuke Sugano (University of Tokyo)</s>-->
<!--                    </td>-->
<!--                </tr>-->
<!--                <tr class="noline">-->
<!--                    <td></td>-->
<!--                    <td></td>-->
<!--                    &lt;!&ndash;<td>9:20am - 10:05am</td>&ndash;&gt;-->
<!--                    <td><s>Jean-Marc Odobez (Idiap and EPFL)</s></td>-->
<!--                </tr>-->
                <tr>
                    <td>3</td>
                    <td>10:40am - 11:10am</td>
                    <td>Invited Speaker II</td>
                </tr>
                <tr>
                    <td>4</td>
                    <td>11:10am - 11:50am</td>
                    <td>Invited Speaker III</td>
                </tr>
                <tr>
                    <td>5</td>
                    <td>11:50am - 12:00pm</td>
                    <td>Panel Discussion</td>
                </tr>

                <tr>
                    <td>6</td>
                    <td>13:00pm - 17:00pm</td>
                    <td>Oral Presentation</td>
                </tr>
                </tbody>
            </table>
        </div>
    </div>

    <hr>
    <div class="row" id="speakers">
        <div class="col-xs-12">
            <h2>Invited Keynote Speakers</h2>
            <div class="row speaker" id="yusuke">
                <div class="col-sm-3 speaker-pic">
                    <a href="https://cvpr.kmu.ac.kr/member.htm">
                        <img class="people-pic" src="images/bcko.jpg">
                    </a>
                    <div class="people-name">
                        <a href="https://cvpr.kmu.ac.kr/member.htm">Byoung Chul Ko</a>
                        <h6>Keimyung University</h6>
                    </div>
                </div>
                <div class="col-md-9">
                    <h4>Graph Convolution Neural Network Based Data association for Online Multi-Object Tracking</h4>
                    <br>
                    <b>Abstract</b>
                    <p class="speaker-abstract">
                        A graph convolutional network (GCN)-based multi-object tracking (MOT) algorithm, consisting of a module for extracting the initial features and a module for updating the features, that estimates the affinity between nodes is proposed. The feature extraction module utilizes the pose feature of the object such that the tracking is correct even when the object is partially occluded. Unlike previous graph neural network (GNN)-based MOT methods, this study is based on a GCN and includes a new feature update mechanism, which is updated by combining the output of the neural network and the node similarity between the tracker and detection nodes for each layer. The node feature is updated by aggregating the updated edge feature and the connection strength between the tracker and detection. In each GCN layer, the three networks for the node, edge update, and edge classification were designed to minimize the network parameters to enable faster MOT compared to other GCN-based MOTs. The entire GCN network was designed to learn end-to-end through an affinity loss. The experimental results for the MOT16 and 17 challenge datasets show that the proposed method achieves a superior or similar performance in terms of tracking accuracy and speed compared to state-of-the-art methods, including GCN-based MOT.
                    </p>
                    <b>Biography</b>
                    <p class="speaker-bio">

                    </p>
                </div>
            </div>
        </div>
    </div>


    <hr>
    <div class="row" id="papers">
        <div class="col-xs-12">
            <h2>Accepted Papers</h2>

            <div class="paper">
                <span class="title">Title</span>
                <span class="authors">Authors</span>
                <div class="btn-group btn-group-xs" role="group">
                    <!--<button class="btn btn-poster-id">Poster #118</button>-->
                    <a class="btn btn-default" target="_blank"
                       href=""><i
                            class="fas fa-file-pdf" aria-hidden="true"></i> PDF </a>
                    <!--<a class="btn btn-default" target="_blank" href="https://github.com/NVlabs/few_shot_gaze"><i class="fas fa-code"></i> Code</a>-->
                </div>
            </div>

<!--            <div class="paper">-->
<!--                <span class="title">A Generalized and Robust Method Towards Practical Gaze Estimation on Smart Phone</span>-->
<!--                <span class="authors">Tianchu Guo, Yongchao Liu, Hui Zhang, Xiabing Liu, Youngjun Kwak, ByungIn Yoo, Jae-Joon Han, Changkyu Choi</span>-->
<!--                <div class="btn-group btn-group-xs" role="group">-->
<!--                    &lt;!&ndash;<button class="btn btn-poster-id">Poster #118</button>&ndash;&gt;-->
<!--                    <a class="btn btn-default" target="_blank"-->
<!--                       href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/GAZE/Guo_A_Generalized_and_Robust_Method_Towards_Practical_Gaze_Estimation_on_ICCVW_2019_paper.pdf"><i-->
<!--                            class="fas fa-file-pdf" aria-hidden="true"></i> PDF </a>-->
<!--                    &lt;!&ndash;<a class="btn btn-default" target="_blank" href="https://github.com/NVlabs/few_shot_gaze"><i class="fas fa-code"></i> Code</a>&ndash;&gt;-->
<!--                </div>-->
<!--            </div>-->

<!--            <div class="paper">-->
<!--                <span class="title">A Generalized and Robust Method Towards Practical Gaze Estimation on Smart Phone</span>-->
<!--                <span class="authors">Tianchu Guo, Yongchao Liu, Hui Zhang, Xiabing Liu, Youngjun Kwak, ByungIn Yoo, Jae-Joon Han, Changkyu Choi</span>-->
<!--                <div class="btn-group btn-group-xs" role="group">-->
<!--                    &lt;!&ndash;<button class="btn btn-poster-id">Poster #118</button>&ndash;&gt;-->
<!--                    <a class="btn btn-default" target="_blank"-->
<!--                       href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/GAZE/Guo_A_Generalized_and_Robust_Method_Towards_Practical_Gaze_Estimation_on_ICCVW_2019_paper.pdf"><i-->
<!--                            class="fas fa-file-pdf" aria-hidden="true"></i> PDF </a>-->
<!--                    &lt;!&ndash;<a class="btn btn-default" target="_blank" href="https://github.com/NVlabs/few_shot_gaze"><i class="fas fa-code"></i> Code</a>&ndash;&gt;-->
<!--                </div>-->
<!--            </div>-->
        </div>
    </div>

<!--    <hr>-->
<!--    <div class="row">-->
<!--        <div class="col-xs-12">-->
<!--            <h2>Accepted Posters</h2>-->
<!--            <div class="paper">-->
<!--                <span class="title">A Generalized and Robust Method Towards Practical Gaze Estimation on Smart Phone</span>-->
<!--                <span class="authors">Tianchu Guo, Yongchao Liu, Hui Zhang, Xiabing Liu, Youngjun Kwak, ByungIn Yoo, Jae-Joon Han, Changkyu Choi</span>-->
<!--                <div class="btn-group btn-group-xs" role="group">-->
<!--                    &lt;!&ndash;<button class="btn btn-poster-id">Poster #118</button>&ndash;&gt;-->
<!--                    <a class="btn btn-default" target="_blank"-->
<!--                       href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/GAZE/Guo_A_Generalized_and_Robust_Method_Towards_Practical_Gaze_Estimation_on_ICCVW_2019_paper.pdf"><i-->
<!--                            class="fas fa-file-pdf" aria-hidden="true"></i> PDF </a>-->
<!--                    &lt;!&ndash;<a class="btn btn-default" target="_blank" href="https://github.com/NVlabs/few_shot_gaze"><i class="fas fa-code"></i> Code</a>&ndash;&gt;-->
<!--                </div>-->
<!--            </div>-->
<!--            <div class="paper">-->
<!--                <span class="title">A Generalized and Robust Method Towards Practical Gaze Estimation on Smart Phone</span>-->
<!--                <span class="authors">Tianchu Guo, Yongchao Liu, Hui Zhang, Xiabing Liu, Youngjun Kwak, ByungIn Yoo, Jae-Joon Han, Changkyu Choi</span>-->
<!--                <div class="btn-group btn-group-xs" role="group">-->
<!--                    &lt;!&ndash;<button class="btn btn-poster-id">Poster #118</button>&ndash;&gt;-->
<!--                    <a class="btn btn-default" target="_blank"-->
<!--                       href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/GAZE/Guo_A_Generalized_and_Robust_Method_Towards_Practical_Gaze_Estimation_on_ICCVW_2019_paper.pdf"><i-->
<!--                            class="fas fa-file-pdf" aria-hidden="true"></i> PDF </a>-->
<!--                    &lt;!&ndash;<a class="btn btn-default" target="_blank" href="https://github.com/NVlabs/few_shot_gaze"><i class="fas fa-code"></i> Code</a>&ndash;&gt;-->
<!--                </div>-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->

    <hr>
    <div class="row" id="organizers">
        <div class="col-xs-12">
            <h2>Organizers</h2>
        </div>
    </div>
    <br>
    <div class="row">
<!--        <div class="col-xs-1"></div>-->
        <div class="col-xs-2">
            <a href="http://203.247.8.200/index.php/Faculty:Jong-Ha_Lee_(KR)">
                <img class="people-pic" src="images/250px-Lee5.jpg">
            </a>
            <div class="people-name">
                <a href="http://203.247.8.200/index.php/Faculty:Jong-Ha_Lee_(KR)">Jong-Ha Lee</a>
                <h6>Keimyung University</h6>
            </div>
        </div>
        <div class="col-xs-2">
            <a href="https://cvpr.kmu.ac.kr/member.htm">
                <img class="people-pic" src="images/bcko.jpg">
            </a>
            <div class="people-name">
                <a href="https://cvpr.kmu.ac.kr/member.htm">Byoung Chul Ko</a>
                <h6>Keimyung University</h6>
            </div>
        </div>

    </div>

    <hr>
    <div class="row">
        <div class="col-xs-12">
            <h2>Program Committee</h2>
            <br>
            <div class="row">
                <div class="col-xs-3">
                    <div class="people-name"><a target="_blank" href="http://nisl.kmu.ac.kr/">Yo Han Park</a><h6>
                        Keimyung University</h6></div>
                    <div class="people-name"><a target="_blank"
                                                href="https://sites.google.com/view/dwoolee/deokwoo-lee?authuser=0">Deokwoo
                        Lee</a><h6>Keimyung University</h6></div>
                    <div class="people-name"><a target="_blank" href="https://wwwfr.uni.lu/snt/people/djamila_aouada">Djamila
                        Aouada</a><h6>Universit√© du Luxembourg</h6></div>
                    <div class="people-name"><a target="_blank" href="https://hyungjinchang.wordpress.com/">Hyung Jin
                        Chang</a><h6>University of Birmingham</h6></div>
                    <div class="people-name"><a target="_blank" href="Chang-Hee Won">Chang-Hee Won</a><h6>Temple
                        University</h6></div>
                </div>
                <div class="col-xs-3">
                    <div class="people-name"><a target="_blank"
                                                href="https://engineering.nyu.edu/faculty/shivendra-panwar">Shivendra
                        Panwar</a><h6>New York University</h6></div>
                    <div class="people-name"><a target="_blank" href="https://sites.google.com/site/youngjunguh">Youngjung
                        Uh</a><h6>Yonsei University</h6></div>
                    <div class="people-name"><a target="_blank" href="https://www.etri.re.kr/eng/main/main.etri">Jang-Hee
                        Yoo</a><h6>ETRI</h6></div>
                    <div class="people-name"><a target="_blank" href="https://www.etri.re.kr/eng/main/main.etri">Kwangju
                        Kim</a><h6>ETRI</h6></div>
                    <div class="people-name"><a target="_blank" href="https://www.etri.re.kr/eng/main/main.etri">InSoo
                        Jang</a><h6>ETRI</h6></div>
                </div>
                <div class="col-xs-3">
                    <div class="people-name"><a target="_blank">Changsu Lee</a><h6>Youngnam University</h6></div>
                    <div class="people-name"><a target="_blank">SooYoung Kwak</a><h6>Hanbat University</h6></div>
                    <div class="people-name"><a target="_blank" href="https://ait.ethz.ch/people/spark/">Inkyu Park</a>
                        <h6>Inha University</h6></div>
                    <div class="people-name"><a target="_blank" href="https://natanielruiz.github.io/">SangHyun Park</a>
                        <h6>DIGIST</h6></div>
                </div>
            </div>
        </div>
    </div>

    <hr>
    <div class="row">
        <div class="col-xs-12">
            <h2>Acknowledgments</h2>
            <br>
            This workshop is proudly sponsored by <a href="https://cvpr.kmu.ac.kr/KAIFRI/">KMU(Keimyung University) Research Institute of AI fusion</a>.
        </div>
    </div>

    <hr>
    <div class="row">
        <div class="col-xs-12">
            <h2>Contact</h2>
            <br>
            For any related question, please contact Prof. Jong-Ha Lee (+82-10-8968-8769, segeberg@kmu.ac.kr)
        </div>
    </div>

</div>

</body>
</html>
